{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOcDHQMif22EtURf8ooqYPP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amrutak2/Deep-Learning/blob/main/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7reZJYaWy-tO"
      },
      "source": [
        "Amruta Kulkarni-20MAI0027\n",
        "\n",
        "Q2. Write a python code to implement the VGG 16 .  \n",
        "•\tDataset as any image dataset but here you have to add the data augmentation (Eg: 10000images then make as 15000images using data augmentation scheme).\n",
        "•\tInclude batch normalization at the anyplace followed by first convolution \n",
        "•\tOptimization sgd\n",
        "\n",
        "Github: \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DL5Teg9d1eM",
        "outputId": "b8ba00e7-f520-459e-c6eb-d8e67834cc3d"
      },
      "source": [
        "# We first load the necessary libraries, the dataset and reshape its dimensons to the minimum allowed by the VGG16 --> (48,48,3)\n",
        "import tensorflow as tf\n",
        "from keras import callbacks\n",
        "from keras import optimizers\n",
        "from keras.engine import Model\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.applications import VGG16\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "input_shape = (48, 48, 3)\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "Y_train = to_categorical(y_train)\n",
        "Y_test = to_categorical(y_test)\n",
        "# resize train set\n",
        "X_train_resized = []\n",
        "for img in X_train:\n",
        "  X_train_resized.append(np.resize(img, input_shape) / 255)\n",
        "  \n",
        "X_train_resized = np.array(X_train_resized)\n",
        "print(X_train_resized.shape)\n",
        "# resize test set\n",
        "X_test_resized = []\n",
        "for img in X_test:\n",
        "  X_test_resized.append(np.resize(img, input_shape) / 255)\n",
        "  \n",
        "X_test_resized = np.array(X_test_resized)\n",
        "print(X_test_resized.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 48, 48, 3)\n",
            "(10000, 48, 48, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Khjbd7dSebGe",
        "outputId": "dfee4afe-5a37-4142-9559-f6f27e2e4f9c"
      },
      "source": [
        "# We build the base model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "base_model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqNUhgY8edsa",
        "outputId": "3302d31b-d9ae-4ba6-c3c2-f6419fbf768c"
      },
      "source": [
        "# We freeze every layer in our base model so that they do not train, we want that our feature extractor stays as before --> transfer learning\n",
        "for layer in base_model.layers: \n",
        "  layer.trainable = False\n",
        "  print('Layer ' + layer.name + ' frozen.')\n",
        "# We take the last layer of our the model and add it to our classifier\n",
        "last = base_model.layers[-1].output\n",
        "x = Flatten()(last)\n",
        "x = Dense(1000, activation='relu', name='fc1')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(10, activation='softmax', name='predictions')(x)\n",
        "model = Model(base_model.input, x)\n",
        "# We compile the model\n",
        "model.compile(optimizer=SGD(lr=1e-4, momentum=0.9), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer input_1 frozen.\n",
            "Layer block1_conv1 frozen.\n",
            "Layer block1_conv2 frozen.\n",
            "Layer block1_pool frozen.\n",
            "Layer block2_conv1 frozen.\n",
            "Layer block2_conv2 frozen.\n",
            "Layer block2_pool frozen.\n",
            "Layer block3_conv1 frozen.\n",
            "Layer block3_conv2 frozen.\n",
            "Layer block3_conv3 frozen.\n",
            "Layer block3_pool frozen.\n",
            "Layer block4_conv1 frozen.\n",
            "Layer block4_conv2 frozen.\n",
            "Layer block4_conv3 frozen.\n",
            "Layer block4_pool frozen.\n",
            "Layer block5_conv1 frozen.\n",
            "Layer block5_conv2 frozen.\n",
            "Layer block5_conv3 frozen.\n",
            "Layer block5_pool frozen.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 1000)              513000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 15,237,698\n",
            "Trainable params: 523,010\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_srcfWvveg3N",
        "outputId": "33d457bc-35a8-4594-889c-4a3689c7f640"
      },
      "source": [
        "# We start the training\n",
        "epochs = 5\n",
        "batch_size = 256\n",
        "# We train it\n",
        "model.fit(X_train_resized, Y_train,\n",
        "          epochs=epochs)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 1204s 769ms/step - loss: 0.4429 - accuracy: 0.0956\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 1195s 764ms/step - loss: 0.3256 - accuracy: 0.1323\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 1190s 762ms/step - loss: 0.3208 - accuracy: 0.1579\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 1188s 760ms/step - loss: 0.3165 - accuracy: 0.1783\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 1211s 775ms/step - loss: 0.3132 - accuracy: 0.1983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc1f6dac450>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHiLTJvNehi7",
        "outputId": "12e72c1f-4e2a-45a4-915a-69764abf32f4"
      },
      "source": [
        "# We evaluate the accuracy and the loss in the test set\n",
        "scores = model.evaluate(X_test_resized, Y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 248s 792ms/step - loss: 0.3056 - accuracy: 0.2682\n",
            "Test loss: 0.30558446049690247\n",
            "Test accuracy: 0.26820001006126404\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}